# 1.  Review at least one article from both “Ethics in the workplace” and “Ethics in Technology” sections below and write how each of them relates to ethics in technology.
## --> Ethics in the workplace and Ethics in Technology , The two are interrelated and complement each other because ethics within the work environment is important and ethics also at work and the use of modern technology is also important, so these two concepts are interconnected together.
#  2.  Do you agree or disagree with these articles?  
## --> yes , I am a gree
# 3.  What stuck out to you specifically from each article?
## --> When we are harmed in the work environment, we must take action. Honesty and honesty are very important in the work environment.

# Code of Ethics
# -- >  Code of Ethics
## 1. GENERAL ETHICAL PRINCIPLES.

### 1.1 Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.
- [x] This principle, which concerns the quality of life of all people, affirms an obligation of computing professionals, both individually and collectively.
- [x]  An essential aim of computing professionals is to minimize negative consequences of computing.
- [x]  Computing professionals should consider whether the results of their efforts will respect diversity, will be used in socially responsible ways.
- [x]  In addition to a safe social environment, human well-being requires a safe natural environment. 
### 1.2 Avoid harm.
- [x]  "harm" means negative consequences, especially when those consequences are significant and unjust.
- [x]  The  harm include unjustified physical or mental injury, unjustified destruction or disclosure of information.
- [x]  Well-intended actions, including those that accomplish assigned duties, may lead to harm. 
- [x] When that harm is unintended, those responsible are obliged to undo or mitigate the harm as much as possible.
- [x]  Avoiding harm begins with careful consideration of potential impacts on all those affected by decisions.
- [x]  When harm is an intentional part of the system, those responsible are obligated to ensure that the harm is ethically justified. 
- [x]  To minimize the possibility of indirectly or unintentionally harming others, computing professionals should follow generally accepted best practices unless there is a compelling ethical reason to do otherwise. 


### 1.3 Be honest and trustworthy.
- [x]  Honesty is an essential component of trustworthiness.
- [x] A computing professional should be transparent and provide full disclosure of all pertinent system capabilities.
- [x]  Computing professionals should be honest about their qualifications, and about any limitations in their competence to complete a task.
- [x]  Computing professionals should not misrepresent an organization's policies or procedures, and should not speak on behalf of an organization unless authorized to do so.

### 1.4 Be fair and take action not to discriminate.
- [x]  The values of equality, tolerance, respect for others, and justice govern this principle. 
- [x]  Fairness requires that even careful decision processes provide some avenue for redress of grievances.

# Ethics in the workplace
# --> Project Dragonfly, Google’s censored search engine
## The employee backlash over Google’s censored search engine for China, explained
### Doing business in China is good for shareholders, bad for humanity
- [x] It’s no mystery why Google executives want to do business with Chinese government officials: It’s profitable.
- [x]  With its population at 1.3 billion, China has the largest number of internet users in the world, so breaking into the Chinese market has been a long-time goal for Silicon Valley tech giants in their quest to find new users and to grow profits.
- [x] But working in China inevitably raises ethical issues for any US company.
- [x]  Doing business in mainland China means making deals with an authoritarian government that has a record of human rights abuses and a strict suppression of speech.
- [x] Despite this, Silicon Valley tech companies have shown a willingness to put aside their idealism — or rationalize their decisions to court Beijing.
- [x]  LinkedIn, for example, has a presence in China because it agreed to block certain online content.
# --> Google and AI 
## Google Backtracks, Says Its AI Will Not Be Used for Weapons or Surveillance
### 1. Google is committing to not using artificial intelligence for weapons or surveillance after employees protested the company’s involvement in Project Maven, a Pentagon pilot program that uses artificial intelligence to analyze drone footage. 

### 2.  Google says it will continue to work with the United States military on cybersecurity, search and rescue, and other non-offensive projects.

### 3. Google CEO Sundar Pichai announced the change in a set of AI principles released today.

### 4.  The principles are intended to govern Google’s use of artificial intelligence and are a response to employee pressure on the company to create guidelines for its use of AI.

# --> The code I’m still ashamed of
## ---> As developer, one of the last lines of defense against potentially dangerous and unethical practices.

### --->  approaching a time where software will drive the vehicle that transports your family to soccer practice.
### --->  There are already AI programs that help doctors diagnose disease.
### ---> It’s not hard to imagine them recommending prescription drugs soon, too.

### --->The more software continues to take over every aspect of our lives, the more important it will be for us to take a stand and ensure that our ethics are ever-present in our code.


# Ethics in Technology
# --> Will Democracy Survive Big Data and Artificial Intelligence?
## Enlightenment is man’s emergence from his self-imposed immaturity. 
## Immaturity is the inability to use one’s understanding without guidance from another.
## Several types of institutions should be considered. Most importantly, society must be decentralized.
## following the principle of subsidiarity. Three dimensions matter.

## 1. Spatial decentralization
-  consists in vibrant federalism.
-  The provinces, regions and communes must be given sufficient autonomy. 
- To a large extent, they must be able to set their own tax rates and govern their own public expenditure.
## 2. Functional decentralization 
- according to area of public expenditure (for example education, health, environment, water provision, traffic, culture etc) is also desirable. 
- This concept has been developed through the proposal of FOCJ, or “Functional, Overlapping and Competing Jurisdictions”.
## 3. Political decentralization 
- relating to the division of power between the executive (government), legislative (parliament) and the courts. 
- Public media and academia should be additional pillars.

# Tech Company Principles
# --> Microsoft AI Principles
## responsible AI principles into practice through the Office of Responsible AI (ORA), the AI, Ethics, and Effects in Engineering and Research (Aether) Committee, and Responsible AI Strategy in Engineering (RAISE). 
## The Aether Committee advises  leadership on the challenges and opportunities presented by AI innovations.
## ORA sets our rules and governance processes, working closely with teams across the company to enable the effort.
## RAISE is a team that enables the implementation of Microsoft responsible AI rules across engineering groups.

# ---> Ethical OS Toolkit
## As technologists, it’s only natural that we spend most of our time focusing on how our tech will change the world for the better. Which is great.
## Everyone loves a sunny disposition. But perhaps it’s more useful, in some ways, to consider the glass half empty.
## What if, in addition to fantasizing about how our tech will save the world, we spent some time dreading all the ways it might, possibly, perhaps, just maybe, screw everything up?
## No one can predict exactly what tomorrow will bring (though somewhere in the tech world, someone is no doubt working on it). 
## So until we get that crystal ball app, the best we can hope to do is anticipate the long-term social impact and unexpected uses of the tech we create today.

## What’s in the Toolkit:
- [x] A checklist of 8 risk zones to help you identify the emerging areas of risk and social harm most critical for your team to start considering now.
- [x] 14 scenarios to spark conversation and stretch your imagination about the long-term impacts of tech you’re building today.
- [x] 7 future-proofing strategies to help you take ethical action today.

# ---> Google AI Principles
## Objectives for AI applications
### We will assess AI applications in view of the following objectives. We believe that AI should:

### 1. Be socially beneficial. 

- [x]  The expanded reach of new technologies increasingly touches society as a whole.
- [x]  Advances in AI will have transformative impacts in a wide range of fields, including healthcare, security, energy, transportation, manufacturing, and entertainment. 
- [x]  AI also enhances our ability to understand the meaning of content at scale. 
### 2. Avoid creating or reinforcing unfair bias.

- [x]  AI algorithms and datasets can reflect, reinforce, or reduce unfair biases. -
 [x]  recognize that distinguishing fair from unfair biases is not always simple, and differs across cultures and societies. 
 - [x]  seek to avoid unjust impacts on people, particularly those related to sensitive characteristics such as race, ethnicity, gender, nationality, income, sexual orientation, ability, and political or religious belief.

### 3. Be built and tested for safety.

- [x]   continue to develop and apply strong safety and security practices to avoid unintended results that create risks of harm. 
- [x]  design our AI systems to be appropriately cautious, and seek to develop them in accordance with best practices in AI safety research.
- [x]  In appropriate cases, we will test AI technologies in constrained environments and monitor their operation after deployment.

### 4. Be accountable to people.

- [x]  design AI systems that provide appropriate opportunities for feedback, relevant explanations, and appeal. 
- [x]  Our AI technologies will be subject to appropriate human direction and control.

### 5. Incorporate privacy design principles.

- [x]  incorporate our privacy principles in the development and use of our AI technologies. 
- [x]  give opportunity for notice and consent, encourage architectures with privacy safeguards, and provide appropriate transparency and control over the use of data.